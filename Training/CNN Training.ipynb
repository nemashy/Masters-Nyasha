{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd016d30091bb45856a94ae619e5d9410e3445f74495848a8805ee5ad5ec3b0e2cd",
   "display_name": "Python 3.8.5 64-bit ('masters': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/nyasha/Desktop/Masters-Nyasha/Models')\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from DatasetCreator import HAVSDataset\n",
    "\n",
    "from CAE import *\n",
    "from training_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training, validation and testing data\n",
    "compressed_file_path = \"C:/Users/nyasha/Desktop/Masters-Nyasha/Processed Data/processed_data.npz\"\n",
    "x_train, x_test, x_val, y_train, y_test, y_val = get_train_test_data(compressed_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(11035, 128, 44)\n(3679, 128, 44)\n(3679, 128, 44)\n(11035,)\n(3679,)\n(3679,)\n"
     ]
    }
   ],
   "source": [
    "# Check if files have been imported correctly\n",
    "print(x_train.shape)  \n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape) \n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "np.amax(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor()\n",
    "    ])\n",
    "# Create the datasets\n",
    "train_dataset = HAVSDataset(x_train, y_train, transform=transform)\n",
    "val_dataset = HAVSDataset(x_val, y_val, transform=transform)\n",
    "test_dataset = HAVSDataset(x_test, y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(32 * 30 * 9, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 30 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(20,20, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(20 * 16 *8, 128),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a model from ../Models\n",
    "model_1  = Net() #ConvNet1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_loader)\n",
    "images, _ = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "device = get_device() \n",
    "model_on_device = model_1.to(device) # Move model to the current device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleAttributeError",
     "evalue": "'Net' object has no attribute 'layer1'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-693105b6b607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\masters\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'Net' object has no attribute 'layer1'"
     ]
    }
   ],
   "source": [
    "x = model_1.layer1(images)\n",
    "print(x.shape)\n",
    "x = model_1.layer2(x)\n",
    "print(x.shape)\n",
    "x = model_1.layer3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 32, 30, 9])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "x = model_1.pool(F.relu(model_1.conv1(images)))\n",
    "x = model_1.pool(F.relu(model_1.conv2(x)))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nyasha\\anaconda3\\envs\\masters\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=['2_walking' 'clutter/noise' 'running' 'sphere_swing' 'vehicle' 'walking'], y=['walking' 'vehicle' 'sphere_swing' ... 'sphere_swing' 'walking' 'vehicle'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "class_weights = get_class_weights(y_train, device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.SGD(model_on_device.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.4124, 0.8343, 2.2706, 0.6050], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=13440, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model_on_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/50 \t Training Loss: 1.2708, Accuracy: 20.52, Testing Loss: 1.7914, Accuracy: 23.97\n",
      "Epoch: 2/50 \t Training Loss: 1.2699, Accuracy: 21.38, Testing Loss: 1.7909, Accuracy: 13.54\n",
      "Epoch: 3/50 \t Training Loss: 1.2697, Accuracy: 17.49, Testing Loss: 1.7896, Accuracy: 23.97\n",
      "Epoch: 4/50 \t Training Loss: 1.2684, Accuracy: 19.61, Testing Loss: 1.7875, Accuracy: 18.10\n",
      "Epoch: 5/50 \t Training Loss: 1.2668, Accuracy: 22.33, Testing Loss: 1.7833, Accuracy: 15.77\n",
      "Epoch: 6/50 \t Training Loss: 1.2596, Accuracy: 24.29, Testing Loss: 1.7699, Accuracy: 17.04\n",
      "Epoch: 7/50 \t Training Loss: 1.2265, Accuracy: 28.26, Testing Loss: 1.6651, Accuracy: 28.81\n",
      "Epoch: 8/50 \t Training Loss: 1.1966, Accuracy: 29.66, Testing Loss: 1.6718, Accuracy: 38.46\n",
      "Epoch: 9/50 \t Training Loss: 1.1967, Accuracy: 28.33, Testing Loss: 1.7516, Accuracy: 23.16\n",
      "Epoch: 10/50 \t Training Loss: 1.1486, Accuracy: 36.14, Testing Loss: 1.5818, Accuracy: 28.21\n",
      "Epoch: 11/50 \t Training Loss: 0.9904, Accuracy: 40.67, Testing Loss: 1.3508, Accuracy: 42.81\n",
      "Epoch: 12/50 \t Training Loss: 0.9038, Accuracy: 47.84, Testing Loss: 1.2389, Accuracy: 49.12\n",
      "Epoch: 13/50 \t Training Loss: 0.9012, Accuracy: 46.81, Testing Loss: 1.1536, Accuracy: 50.53\n",
      "Epoch: 14/50 \t Training Loss: 0.8334, Accuracy: 50.44, Testing Loss: 1.1063, Accuracy: 51.24\n",
      "Epoch: 15/50 \t Training Loss: 0.7109, Accuracy: 57.87, Testing Loss: 1.4063, Accuracy: 42.67\n",
      "Epoch: 16/50 \t Training Loss: 0.6911, Accuracy: 58.29, Testing Loss: 0.8490, Accuracy: 67.93\n",
      "Epoch: 17/50 \t Training Loss: 0.5476, Accuracy: 67.17, Testing Loss: 1.3507, Accuracy: 53.00\n",
      "Epoch: 18/50 \t Training Loss: 0.7765, Accuracy: 53.67, Testing Loss: 0.8497, Accuracy: 60.83\n",
      "Epoch: 19/50 \t Training Loss: 0.5246, Accuracy: 67.73, Testing Loss: 0.7343, Accuracy: 70.32\n",
      "Epoch: 20/50 \t Training Loss: 0.4837, Accuracy: 71.48, Testing Loss: 0.6856, Accuracy: 72.38\n",
      "Epoch: 21/50 \t Training Loss: 0.5014, Accuracy: 70.37, Testing Loss: 0.7336, Accuracy: 71.65\n",
      "Epoch: 22/50 \t Training Loss: 0.4625, Accuracy: 73.60, Testing Loss: 0.6274, Accuracy: 75.16\n",
      "Epoch: 23/50 \t Training Loss: 0.4497, Accuracy: 73.38, Testing Loss: 0.7085, Accuracy: 71.11\n",
      "Epoch: 24/50 \t Training Loss: 0.4318, Accuracy: 74.89, Testing Loss: 0.6305, Accuracy: 75.16\n",
      "Epoch: 25/50 \t Training Loss: 0.4320, Accuracy: 74.44, Testing Loss: 0.6456, Accuracy: 74.59\n",
      "Epoch: 26/50 \t Training Loss: 0.4351, Accuracy: 73.90, Testing Loss: 0.5886, Accuracy: 74.91\n",
      "Epoch: 27/50 \t Training Loss: 0.3914, Accuracy: 76.62, Testing Loss: 0.5775, Accuracy: 76.38\n",
      "Epoch: 28/50 \t Training Loss: 0.3820, Accuracy: 77.34, Testing Loss: 0.6058, Accuracy: 76.87\n",
      "Epoch: 29/50 \t Training Loss: 0.3820, Accuracy: 77.31, Testing Loss: 0.5589, Accuracy: 78.77\n",
      "Epoch: 30/50 \t Training Loss: 0.3666, Accuracy: 78.38, Testing Loss: 0.5675, Accuracy: 74.91\n",
      "Epoch: 31/50 \t Training Loss: 0.3701, Accuracy: 78.17, Testing Loss: 0.5626, Accuracy: 78.85\n",
      "Epoch: 32/50 \t Training Loss: 0.3437, Accuracy: 79.66, Testing Loss: 0.5100, Accuracy: 79.21\n",
      "Epoch: 33/50 \t Training Loss: 0.3499, Accuracy: 79.51, Testing Loss: 0.5118, Accuracy: 78.55\n",
      "Epoch: 34/50 \t Training Loss: 0.3760, Accuracy: 78.36, Testing Loss: 0.5511, Accuracy: 77.25\n",
      "Epoch: 35/50 \t Training Loss: 0.3543, Accuracy: 79.17, Testing Loss: 0.5909, Accuracy: 77.66\n",
      "Epoch: 36/50 \t Training Loss: 0.3396, Accuracy: 80.44, Testing Loss: 0.5670, Accuracy: 77.98\n",
      "Epoch: 37/50 \t Training Loss: 0.3241, Accuracy: 80.97, Testing Loss: 0.4894, Accuracy: 80.67\n",
      "Epoch: 38/50 \t Training Loss: 0.3122, Accuracy: 81.92, Testing Loss: 0.4729, Accuracy: 80.48\n",
      "Epoch: 39/50 \t Training Loss: 0.3113, Accuracy: 82.20, Testing Loss: 0.5059, Accuracy: 78.53\n",
      "Epoch: 40/50 \t Training Loss: 0.3177, Accuracy: 81.81, Testing Loss: 0.4874, Accuracy: 79.37\n",
      "Epoch: 41/50 \t Training Loss: 0.3156, Accuracy: 81.86, Testing Loss: 0.4682, Accuracy: 80.89\n",
      "Epoch: 42/50 \t Training Loss: 0.3083, Accuracy: 83.00, Testing Loss: 0.4610, Accuracy: 80.62\n",
      "Epoch: 43/50 \t Training Loss: 0.3065, Accuracy: 82.85, Testing Loss: 0.5094, Accuracy: 78.17\n",
      "Epoch: 44/50 \t Training Loss: 0.2918, Accuracy: 83.24, Testing Loss: 0.4992, Accuracy: 80.92\n",
      "Epoch: 45/50 \t Training Loss: 0.2805, Accuracy: 83.78, Testing Loss: 0.4360, Accuracy: 82.98\n",
      "Epoch: 46/50 \t Training Loss: 0.2843, Accuracy: 84.16, Testing Loss: 0.5072, Accuracy: 79.51\n",
      "Epoch: 47/50 \t Training Loss: 0.2664, Accuracy: 84.33, Testing Loss: 0.4745, Accuracy: 80.95\n",
      "Epoch: 48/50 \t Training Loss: 0.3001, Accuracy: 82.79, Testing Loss: 0.5125, Accuracy: 80.78\n",
      "Epoch: 49/50 \t Training Loss: 0.2635, Accuracy: 84.89, Testing Loss: 0.5959, Accuracy: 73.93\n",
      "Epoch: 50/50 \t Training Loss: 0.2620, Accuracy: 84.68, Testing Loss: 0.4655, Accuracy: 82.44\n"
     ]
    }
   ],
   "source": [
    "train_model(50, train_loader, val_loader, criterion, optimizer, device, model_on_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.4445792775729607, 83.31068225061158)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Evaluate model performance on test data\n",
    "evaluate_model(test_loader, device, model_on_device, criterion)"
   ]
  }
 ]
}