{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from torch2trt import TRTModule\n",
    "from torch2trt import torch2trt\n",
    "from models.CNN import ErnNet\n",
    "from utils import get_pytorch_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_start_points_x(width, slice_width, overlap_x):\n",
    "    x_points = [0]\n",
    "    stride = int(slice_width * (1 - overlap_x))\n",
    "    counter = 1\n",
    "    while True:\n",
    "        pt = stride * counter\n",
    "        if pt + slice_width >= width:\n",
    "            x_points.append(width - slice_width)\n",
    "            break\n",
    "        else:\n",
    "            x_points.append(pt)\n",
    "        counter += 1\n",
    "    return x_points\n",
    "\n",
    "def get_total_inference_time(self, model, num_loops):\n",
    "    \"\"\"Returns the total inference time on all the loops\"\"\"\n",
    "    # Wait for all kernels in all streams on the CUDA device to complete.\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "\n",
    "    # GPU warmup\n",
    "    for _ in range(10):\n",
    "        _ = model(self.input_data_batch)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(num_loops):\n",
    "        _ = model(self.input_data_batch)\n",
    "        torch.cuda.current_stream().synchronize()\n",
    "    t1 = time.time()\n",
    "\n",
    "    return t1 - t0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load model\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('trt_models/model_trt_int8.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "fs = 714 # Sampling frequency\n",
    "nperseg = 128 # Length of each segment\n",
    "noverlap = 64 # Number of overlapping points between segments\n",
    "nfft = 128 # Length of FFT\n",
    "dwell_time = 4\n",
    "num_points = np.int64(np.floor(dwell_time* fs))\n",
    "print(num_points)\n",
    "\n",
    "# Remember what Robert said about 64 and 32 when creating arrays\n",
    "\n",
    "x = np.random.random(num_points) + np.random.random(num_points) * 1j\n",
    "\n",
    "f, t, Zxx = signal.stft(x, fs=fs, window='hamming', nperseg=nperseg, noverlap=noverlap, nfft=nfft, detrend=False, return_onesided=True, boundary='zeros', padded=False, axis=- 1)\n",
    "# plt.pcolormesh(t, f, np.abs(Zxx))\n",
    "\n",
    "fft_dB =20*np.log10(np.abs(Zxx))\n",
    "\n",
    "fft_dB.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2856\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 45)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "714*45"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32130"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "x = torch.randn(3,2, dtype=torch.cfloat)\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.6035-0.7965j, -1.0970+0.3573j],\n",
       "        [-0.0987+0.5487j,  0.1597+1.0346j],\n",
       "        [ 0.4414+0.4647j,  0.8101-0.7251j]])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "x = torch.randn(40000,num_points, dtype=torch.cfloat)\n",
    "print(len(x))\n",
    "\n",
    "# Get the short-term fourier transform of the signal\n",
    "f, t, Zxx = signal.stft(x, fs=fs, window='hamming', nperseg=nperseg, noverlap=noverlap, nfft=nfft, detrend=False, return_onesided=True, boundary='zeros', padded=False, axis=- 1)\n",
    "# plt.pcolormesh(t, f, np.abs(Zxx))\n",
    "\n",
    "Zxx_tensor = torch.from_numpy(Zxx)\n",
    "\n",
    "# print(type(Zxx))\n",
    "# # Converting to dB\n",
    "# Zxx_tensor = torch.from_numpy(Zxx)\n",
    "# fft_dB = 20*torch.log10(torch.abs(Zxx_tensor))\n",
    "# # fft_dB.shape\n",
    "\n",
    "# width = fft_dB.shape[1]\n",
    "# fft_dB.shape\n",
    "\n",
    "\n",
    "Zxx_tensor = torch.from_numpy(Zxx)\n",
    "\n",
    "# Zxx = torch.randn(128,45)\n",
    "\n",
    "# Converting to dB\n",
    "fft_dB = 20*torch.log10(torch.abs(Zxx_tensor))\n",
    "_ = model_trt(fft_dB.cuda())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "num_points"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2856"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ran\n",
    "fs = 714 # Sampling frequency\n",
    "nperseg = 128 # Length of each segment\n",
    "noverlap = 64 # Number of overlapping points between segments\n",
    "nfft = 128 # Length of FFT\n",
    "dwell_time = 4\n",
    "slice_width = 45\n",
    "overlap = 0.5\n",
    "num_points = np.int64(np.floor(dwell_time* fs))\n",
    "classified_imgs = 0\n",
    "\n",
    "\n",
    "torch.cuda.current_stream().synchronize()\n",
    "# GPU warmup\n",
    "for _ in range(100):\n",
    "    _ = model_trt(torch.randn((1, 1, 128, 45)).cuda())\n",
    "\n",
    "# Start counter\n",
    "t0 = time.time()\n",
    "t1 = time.time()\n",
    "while (t1 - t0) < dwell_time:\n",
    "\n",
    "    # Creating the samples\n",
    "    x = torch.randn(num_points, dtype=torch.cfloat)\n",
    "    # Get the short-term fourier transform of the signal\n",
    "    f, t, Zxx = signal.stft(x, fs=fs, window='hamming', nperseg=nperseg, noverlap=noverlap, nfft=nfft, detrend=False, return_onesided=True, boundary='zeros', padded=False, axis=-1)\n",
    "    Zxx_tensor = torch.from_numpy(Zxx)\n",
    "\n",
    "    # Zxx = torch.randn(128,45)\n",
    "\n",
    "    # Converting to dB\n",
    "    fft_dB = 20*torch.log10(torch.abs(Zxx_tensor))\n",
    "    _ = model_trt(fft_dB.cuda())\n",
    "\n",
    "    classified_imgs += 1\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "print(classified_imgs-1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nyasha/anaconda3/envs/thesis/lib/python3.8/site-packages/scipy/signal/spectral.py:1812: UserWarning: Input data is complex, switching to return_onesided=False\n",
      "  warnings.warn('Input data is complex, switching to '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8986\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# On cpu\n",
    "# On gpu\n",
    "# On cpu with parallelisation\n",
    "\n",
    "# Show the throttling of the stft function\n",
    "# Review decision in padded=false\n",
    "#\n",
    "num_imgs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# In parallel"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "33000"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "throughput = num_imgs/(t1-t0)\n",
    "point_throughput = throughput * slice_width\n",
    "supported_range_bins = point_throughput/fs\n",
    "supported_range_bins*5"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1969.864781229934"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('thesis': conda)"
  },
  "interpreter": {
   "hash": "c038a02319e44538776f88f6eccb85a8daa469fb892b6db8d0a399f3ecc69bfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}