{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('thesis': conda)"
  },
  "interpreter": {
   "hash": "c038a02319e44538776f88f6eccb85a8daa469fb892b6db8d0a399f3ecc69bfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch2trt import torch2trt\n",
    "\n",
    "from model_training import get_loaders_and_classes, get_train_test_data, get_class_weights\n",
    "from training_functions import *\n",
    "from CNN import ErnNet\n",
    "from utility_functions import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import yaml\n",
    "def read_params(config_path):\n",
    "    with open(config_path) as yaml_file:\n",
    "        config = yaml.safe_load(yaml_file)\n",
    "    return config\n",
    "\n",
    "config = read_params('settings.yaml')\n",
    "batch_size = config['batch_size']\n",
    "num_epochs = config['number_epochs']\n",
    "# Extracting the training, validation and testing data\n",
    "compressed_data_path = config['compressed_data_path']\n",
    "data = decompress_data(compressed_data_path)\n",
    "\n",
    "# Get data loaders\n",
    "data_loaders_and_classes = get_loaders_and_classes(data, batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Extracting the training, validation and testing data\n",
    "x_train = data['x_train']\n",
    "x_val = data['x_val']\n",
    "x_test = data['x_test']\n",
    "\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Residual network model\n",
    "from utility_functions import qrelu, qconv2d\n",
    "\n",
    "# def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1,norm=False,act=False,qat_mode=False,infer=False):\n",
    "#     \"\"\"3x3 convolution with padding\"\"\"\n",
    "#     return qconv2d(in_channels=in_planes,out_channels=out_planes,kernel_size=3,stride=stride,groups=groups,padding=dilation,dilation=dilation,bias=False,act=act,norm=norm,qat=qat_mode,infer=infer)\n",
    "\n",
    "\n",
    "class FirstLayer(nn.Module):\n",
    "    \"\"\"The layer of the network\"\"\"\n",
    "    def __init__(self, num_channels, norm, act, qat_mode, infer):\n",
    "        super(FirstLayer, self).__init__()\n",
    "\n",
    "        # First convolutional layer of the model\n",
    "        self.conv1 = qconv2d(in_channels=1, out_channels=num_channels, kernel_size=3, padding=1, bias=False, act=act, norm=norm, qat=qat_mode, infer=infer)\n",
    "\n",
    "        self.relu = qrelu(inplace=True,qat=qat_mode,infer=infer)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        #out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"A block that will be skipped over by the residual connectionS\"\"\"\n",
    "    def __init__(self, num_channels, norm, act, qat_mode, infer):\n",
    "        super(Block, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.relu = qrelu(inplace=True,qat=qat_mode,infer=infer)\n",
    "        \n",
    "        # First layer of the block\n",
    "        self.conv1 = qconv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=1, padding=1, bias=False, act=act, norm=norm, qat=qat_mode, infer=infer)\n",
    "\n",
    "        # Second layer of the block\n",
    "        self.conv2 = qconv2d(in_channels=1, out_channels=num_channels, kernel_size=3, padding=1, bias=False, act=act, norm=norm, qat=qat_mode, infer=infer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out += identity # Creating the skip connection\n",
    "\n",
    "        return out\n",
    "\n",
    "class ErnNet(nn.Module): # Enerst Net\n",
    "    def __init__(self, num_labels, norm, act, qat_mode, infer, num_channels=32):\n",
    "        super(ErnNet, self).__init__()\n",
    "        #Network = First layer -> block1 -> block2 ....\n",
    "        self.first_layer = FirstLayer(num_channels,norm, act, qat_mode, infer)\n",
    "        self.block1 = Block(num_channels, norm, act, qat_mode, infer)\n",
    "        self.block2 = Block(num_channels, norm, act, qat_mode, infer)\n",
    "        self.block3 = Block(num_channels, norm, act, qat_mode, infer)\n",
    "        self.output_channels = self.block3.num_channels\n",
    "    \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(self.output_channels * 1 * 1, num_labels)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.first_layer(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(-1, self.output_channels * 1 * 1)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = ErnNet(num_labels=6, norm=True, act=True, qat_mode=True, infer=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'num_channels' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-634adb83747c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErnNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqat_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-02637637b5e4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_labels, norm, act, qat_mode, infer, num_channels)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErnNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m#Network = First layer -> block1 -> block2 ....\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFirstLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqat_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqat_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqat_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-02637637b5e4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, norm, act, qat_mode, infer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# First convolutional layer of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqat_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqat_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_channels' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Calibrating model\n",
    "\n",
    "random_idxs_train = np.random.randint(len(x_train), size=100)\n",
    "random_idxs_val = np.random.randint(len(x_val), size=100)\n",
    "random_idxs_test = np.random.randint(len(x_test), size=100)\n",
    "\n",
    "random_examples_train = x_train[random_idxs_train]\n",
    "random_examples_val = x_val[random_idxs_val]\n",
    "random_examples_test = x_train[random_idxs_test]\n",
    "\n",
    "int_8_calib_dataset = torch.from_numpy(np.concatenate((random_examples_train, random_examples_test, random_examples_val)))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "x = torch.rand((batch_size, 1, 128, 45)).cuda()\n",
    "# create some regular pytorch model...\n",
    "network = ErnNet()\n",
    "checkpoint = torch.load('checkpoint.pt')\n",
    "network.load_state_dict(checkpoint)\n",
    "network.eval().cuda()\n",
    "\n",
    "# Creating TensorRT models\n",
    "model_trt = torch2trt(network, [x], max_batch_size=batch_size)\n",
    "model_trt_fp16 = torch2trt(network, [x], fp16_mode=True, max_batch_size=batch_size)\n",
    "model_trt_int8 = torch2trt(network, [x], int8_mode=True, max_batch_size=batch_size, int8_calib_dataset=int_8_calib_dataset)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nyasha/anaconda3/envs/thesis/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Initialising training parameters\n",
    "class_weights = get_class_weights(y_train, 'cuda')\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nyasha/anaconda3/envs/thesis/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['2_walking' 'clutter/noise' 'running' 'sphere_swing' 'vehicle' 'walking'], y=['2_walking' 'sphere_swing' 'vehicle' ... 'clutter/noise' 'running'\n",
      " 'sphere_swing'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def evaluate_model(model_on_device, data_loader, criterion, classes, show_cm=False):\n",
    "\n",
    "    \"\"\"Evaluate Performance on test set\"\"\"\n",
    "    model_on_device.eval()  # Turn off gradient computations\n",
    "    num_batches = len(data_loader)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    y_tot = torch.empty(0)\n",
    "    y_pred_tot = torch.empty(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t0 = time.time()\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images = images.to('cuda').float()\n",
    "            labels = labels.to('cuda')\n",
    "            outputs = model_on_device(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            labels = labels.cpu()\n",
    "            predicted = predicted.cpu()\n",
    "\n",
    "            y_tot = torch.cat((y_tot, labels), 0)\n",
    "            y_pred_tot = torch.cat((y_pred_tot, predicted), 0)\n",
    "        t1 = time.time()\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracy = 100 * correct / total\n",
    "    errors = y_pred_tot - y_tot != 0\n",
    "    y_pred_errors = y_pred_tot[errors]\n",
    "    y_true_errors = y_tot[errors]\n",
    "\n",
    "    # Plotting the Confusion Matrix\n",
    "    if show_cm:\n",
    "        generate_confusion_matrix(classes, y_tot, y_pred_tot)\n",
    "\n",
    "    print(f'Time taken on inference is {(t1-t0)/num_batches}')\n",
    "\n",
    "    return running_loss / num_batches, accuracy, errors, y_pred_errors, y_true_errors\n",
    "\n",
    "\n",
    "def generate_confusion_matrix(classes, y_tot, y_pred_tot):\n",
    "    cm = confusion_matrix(y_tot.numpy(), y_pred_tot.numpy())\n",
    "    num_classes = len(classes)\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    # Coloured confusion matrix\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    cm = confusion_matrix(y_tot.numpy(), y_pred_tot.numpy(), normalize=\"true\")\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "\n",
    "    for (i, j), z in np.ndenumerate(cm):\n",
    "        plt.text(j, i, \"{:0.3f}\".format(z), ha=\"center\", va=\"center\")\n",
    "\n",
    "    plt.xticks(range(num_classes))\n",
    "    plt.yticks(range(num_classes))\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"True\")\n",
    "\n",
    "    plt.gca().set_xticklabels(classes)\n",
    "    plt.gca().set_yticklabels(classes)\n",
    "\n",
    "    plt.title(\"Normalized Confusion Matrix for the Data\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_loader = data_loaders_and_classes['train_loader']\n",
    "val_loader = data_loaders_and_classes['val_loader']\n",
    "test_loader = data_loaders_and_classes['test_loader']\n",
    "classes = data_loaders_and_classes['classes']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Pytorch model\n",
    "_, accuracy, errors, y_pred_errors, y_true_errors = evaluate_model(network, val_loader, criterion, classes, show_cm=False)\n",
    "print(accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time taken on inference is 0.004473873849451189\n",
      "91.81851989587207\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# TRT model FP32\n",
    "_, accuracy, errors, y_pred_errors, y_true_errors = evaluate_model(model_trt, val_loader, criterion, classes, show_cm=False)\n",
    "print(accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time taken on inference is 0.002103014105170436\n",
      "91.81851989587207\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# TRT model FP16\n",
    "_, accuracy, errors, y_pred_errors, y_true_errors = evaluate_model(model_trt_fp16, val_loader, criterion, classes, show_cm=False)\n",
    "print(accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time taken on inference is 0.0015588427436422315\n",
      "92.07883971736705\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# TRT Model INT8\n",
    "_, accuracy, errors, y_pred_errors, y_true_errors = evaluate_model(model_trt_int8, val_loader, criterion, classes, show_cm=False)\n",
    "print(accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time taken on inference is 0.0013057973963269114\n",
      "88.88062476757159\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "network.load_state_dict(checkpoint)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "torch.save(network.state_dict(), 'trt_models/pytorch_model.pth')\n",
    "torch.save(model_trt.state_dict(), 'trt_models/model_trt_fp32.pth')\n",
    "torch.save(model_trt_fp16.state_dict(), 'trt_models/model_trt_fp16.pth')\n",
    "torch.save(model_trt_int8.state_dict(), 'trt_models/model_trt_int8.pth')\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}