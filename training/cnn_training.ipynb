{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %history -g -f \"history.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from model_training import *\n",
    "from utils import *\n",
    "from models.CNN import Model1, Model2, Model3, Model4\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read configurations file\n",
    "config = read_params('settings.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config['batch_size']\n",
    "num_epochs = config['number_epochs']\n",
    "lr = config['lr']\n",
    "transition_steps = config['transition_steps']\n",
    "gamma = config['gamma_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training, validation and testing data\n",
    "compressed_data_path = config['compressed_data_path']\n",
    "data = decompress_data(compressed_data_path)\n",
    "\n",
    "# Get data loaders\n",
    "data_loaders_and_classes = get_loaders_and_classes(data, batch_size)\n",
    "processed_data = np.load(compressed_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model\n",
    "model = Model4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of parameters in model\n",
    "model_total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "# Initialising training parameters\n",
    "class_weights = get_class_weights(data['y_train'], device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Set optimiser\n",
    "optimizer = optim.Adam(model.parameters(), 1e-4)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Scheduling parameters\n",
    "scheduler = Scheduler(optimizer, transition_steps, gamma)\n",
    "lr_scheduler = scheduler.get_MultiStepLR()\n",
    "\n",
    "# Create a model trainer object\n",
    "model_trainer = ModelTrainer(model, criterion, data_loaders_and_classes)\n",
    "model_trainer.scheduler = lr_scheduler # Include Scheduler\n",
    "\n",
    "# Inititate training\n",
    "train_loss_res, train_accuracy_res, validation_loss_res, validation_accuracy_res = model_trainer.train_model(100, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load minimum validation loss model for evaluation\n",
    "model.load_state_dict(torch.load(\"model_ckpt/checkpoint.pt\"))\n",
    "model_on_device = model.to(device) # Move model to Cuda devide\n",
    "_, accuracy, _, _, _ = model_trainer.evaluate_model(model_on_device, data_loaders_and_classes['val_loader'], True) # Evaluate performance of the model\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using the cross validation approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted from https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training, validation and testing data\n",
    "compressed_data_path = config['compressed_cv_data_path']\n",
    "processed_data = np.load(compressed_data_path) # Unzipping\n",
    "x_train_cv = processed_data[\"x_train\"]\n",
    "y_train_cv = processed_data[\"y_train\"]\n",
    "\n",
    "x_test_cv = processed_data[\"x_test\"]\n",
    "y_test_cv = processed_data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = config['num_folds']\n",
    "\n",
    "\n",
    "network = Model4()\n",
    "device = get_device()\n",
    "\n",
    "# Initialising training parameters\n",
    "class_weights = get_class_weights(y_train_cv, device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "train_data = TrainTestData(x_train_cv, y_train_cv)\n",
    "test_data = TrainTestData(x_test_cv, y_test_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_data.get_dataset()\n",
    "train_dataset.enc.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "device = get_device() \n",
    "k_folds = 10\n",
    "num_epochs = 110\n",
    "\n",
    "\n",
    "class_weights = get_class_weights(y_train_cv, device)\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "transforms.ToTensor()\n",
    "])\n",
    "# Create the datasets\n",
    "dataset_train_part = HAVSDataset(x_train_cv, y_train_cv, transform=transform)\n",
    "dataset_test_part = HAVSDataset(x_test_cv, y_test_cv, transform=transform)\n",
    "dataset = dataset_train_part\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=k_folds, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset, y_train_cv)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset, \n",
    "                        batch_size=32, sampler=train_subsampler) # sampler=train_subsampler\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=32, sampler=test_subsampler) # sampler=test_subsampler\n",
    "\n",
    "    # Init the neural network\n",
    "    network = Model4()\n",
    "    network_on_device = network.to(device) # Move model to the current device\n",
    "    network_on_device.apply(reset_weights)\n",
    "\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=20, verbose=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network_on_device.parameters())\n",
    "\n",
    "    # Initialize scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [10,20,30,40,50,60] , gamma=0.8, last_epoch=-1, verbose=True)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets = targets.to(device)\n",
    "  \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform forward pass\n",
    "            outputs = network_on_device(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "            \n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.3f' %\n",
    "                        (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "        # Check early stopping\n",
    "        test_loss, _, _, _, _ = evaluate_model(testloader, device, network_on_device, loss_function)\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "        early_stopping(test_loss, network_on_device)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break           \n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Load last checkpoint (best results)\n",
    "    network.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "    network_on_device = network.to(device)\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}_3.pth'\n",
    "    torch.save(network_on_device.state_dict(), save_path)\n",
    "\n",
    "    # Evaluation for this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            targets = targets.to(device)\n",
    "            # Generate outputs\n",
    "            outputs = network_on_device(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(results.items())} %')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16d30091bb45856a94ae619e5d9410e3445f74495848a8805ee5ad5ec3b0e2cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('masters': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
